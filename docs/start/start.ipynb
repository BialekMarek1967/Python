{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXhctqjgXO7"
      },
      "source": [
        "##### Copyright 2022 The Cirq Developers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z2RJVa8qgXou"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "# Hello Qubit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Ustawienia liczby rdzeni CPU dla TensorFlow\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Ustawienia seedów\n",
        "seed1_datetime = datetime.strptime(\"2024-11-26 20:15:08\", \"%Y-%m-%d %H:%M:%S\")\n",
        "seed2_datetime = datetime.strptime(\"2024-12-03 20:15:08\", \"%Y-%m-%d %H:%M:%S\")\n",
        "seed1 = int(seed1_datetime.timestamp())\n",
        "seed2 = int(seed2_datetime.timestamp())\n",
        "\n",
        "np.random.seed(seed1)\n",
        "tf.random.set_seed(seed1)\n",
        "\n",
        "# Definiowanie target pattern\n",
        "target_pattern = [17,34,38,42,48]\n",
        "iRow = 8_500_000\n",
        "\n",
        "# Generowanie danych (zamiast wczytywania z pliku)\n",
        "data_content = [\n",
        "[5,8,21,37,46],\n",
        "[5,7,12,19,26],\n",
        "[7,8,34,36,38],\n",
        "[5,11,12,27,32],\n",
        "[10,16,30,41,45],\n",
        "[10,13,19,40,45],\n",
        "[29,30,35,41,45],\n",
        "[15,21,38,39,47],\n",
        "[12,18,43,44,46],\n",
        "[4,11,26,32,41],\n",
        "[11,28,34,37,38],\n",
        "[10,15,16,36,44],\n",
        "[6,10,17,18,42],\n",
        "[13,14,16,47,49],\n",
        "[5,8,19,33,36],\n",
        "[10,22,24,33,38],\n",
        "[8,12,27,31,37],\n",
        "[6,9,13,14,25],\n",
        "[9,22,23,34,35],\n",
        "[12,15,18,24,25],\n",
        "[6,11,40,46,48],\n",
        "[3,16,30,34,35],\n",
        "[9,20,21,33,49],\n",
        "[8,22,28,40,42],\n",
        "[15,23,25,46,49],\n",
        "[10,14,15,24,47],\n",
        "[18,29,41,44,49],\n",
        "[5,14,16,34,39],\n",
        "[26,28,40,49,50],\n",
        "[6,11,17,43,49],\n",
        "[6,14,18,19,48],\n",
        "[7,17,18,19,22],\n",
        "[3,5,7,12,31],\n",
        "[25,29,38,41,44],\n",
        "[1,4,7,21,26],\n",
        "[1,21,32,36,50],\n",
        "[2,13,21,24,37],\n",
        "[13,20,22,27,42],\n",
        "[17,28,31,35,39],\n",
        "[11,20,24,25,35],\n",
        "[5,8,22,32,39],\n",
        "[6,20,29,40,45],\n",
        "[6,31,37,41,49],\n",
        "[9,13,21,28,45],\n",
        "[4,13,28,37,38],\n",
        "[2,4,14,26,29],\n",
        "[12,14,17,27,43],\n",
        "[4,9,26,32,40],\n",
        "[3,13,41,46,49],\n",
        "[19,28,29,34,44],\n",
        "[10,12,14,30,43],\n",
        "[4,30,32,41,50],\n",
        "[5,12,21,43,48],\n",
        "[1,22,27,37,50],\n",
        "[22,31,37,38,41],\n",
        "[8,19,22,32,40],\n",
        "[17,18,22,24,25],\n",
        "[11,14,19,23,49],\n",
        "[14,16,28,44,48],\n",
        "[6,9,31,33,35],\n",
        "[4,6,10,13,32],\n",
        "[2,4,9,20,41],\n",
        "[5,9,12,23,40],\n",
        "[6,9,11,29,35],\n",
        "[1,25,46,47,48],\n",
        "[5,14,21,23,50],\n",
        "[6,8,23,33,49],\n",
        "[15,16,17,19,50],\n",
        "[7,27,33,47,48],\n",
        "[7,18,19,33,37],\n",
        "[4,13,19,25,43],\n",
        "[14,23,29,33,37],\n",
        "[7,26,32,34,49],\n",
        "[5,32,33,38,49],\n",
        "[4,10,25,30,47],\n",
        "[6,9,10,17,43],\n",
        "[3,7,20,32,44],\n",
        "[3,10,18,31,43],\n",
        "[2,6,15,18,24],\n",
        "[6,10,21,34,36],\n",
        "[1,7,16,21,48],\n",
        "[2,11,23,29,34],\n",
        "[7,22,24,25,41],\n",
        "[9,25,39,41,46],\n",
        "[7,10,13,26,27],\n",
        "[18,25,28,34,42],\n",
        "[3,19,32,43,48],\n",
        "[1,38,39,42,47],\n",
        "[17,25,32,35,45],\n",
        "[1,8,18,25,47],\n",
        "[9,19,24,28,49],\n",
        "[9,12,22,37,40],\n",
        "[2,15,33,40,43],\n",
        "[1,16,34,36,37],\n",
        "[8,18,22,33,40],\n",
        "[4,7,15,25,29],\n",
        "[4,28,30,36,46],\n",
        "[12,17,29,39,40],\n",
        "[16,18,20,36,49],\n",
        "[19,21,22,28,45],\n",
        "[2,4,21,30,41],\n",
        "[2,17,21,22,45],\n",
        "[7,14,15,20,39],\n",
        "[6,7,9,13,30],\n",
        "[8,18,35,38,42],\n",
        "[10,32,35,38,45],\n",
        "[10,16,28,30,33],\n",
        "[1,7,14,22,44],\n",
        "[12,32,40,44,49],\n",
        "[4,7,10,39,48],\n",
        "[9,31,32,33,34],\n",
        "[1,11,14,22,43],\n",
        "[9,28,36,42,43],\n",
        "[6,21,33,37,47],\n",
        "[7,17,25,26,35],\n",
        "[6,9,19,37,38],\n",
        "[1,8,15,18,39],\n",
        "[6,10,23,33,41],\n",
        "[11,33,35,42,44],\n",
        "[3,10,11,13,42],\n",
        "[3,10,16,35,45],\n",
        "[6,11,15,18,45],\n",
        "[3,10,36,43,47],\n",
        "[5,18,33,38,47],\n",
        "[15,19,21,34,40],\n",
        "[17,38,41,43,47],\n",
        "[19,20,40,42,47],\n",
        "[1,8,9,12,37],\n",
        "[26,31,33,39,40],\n",
        "[2,9,17,25,29],\n",
        "[13,18,20,38,39],\n",
        "[8,26,32,44,50],\n",
        "[8,15,34,44,49],\n",
        "[11,17,20,22,29],\n",
        "[14,24,27,35,39],\n",
        "[3,15,22,26,37],\n",
        "[3,7,27,43,46],\n",
        "[5,13,25,33,35],\n",
        "[22,25,41,45,49],\n",
        "[4,18,35,41,43],\n",
        "[6,16,18,29,35],\n",
        "[11,25,32,42,47],\n",
        "[1,8,15,19,37],\n",
        "[10,11,25,32,49],\n",
        "[2,21,30,39,43],\n",
        "[16,29,38,42,48],\n",
        "[13,19,20,27,41],\n",
        "[1,4,14,32,48],\n",
        "[2,13,14,30,32],\n",
        "[3,4,8,11,41],\n",
        "[3,19,22,37,39],\n",
        "[3,7,14,46,48],\n",
        "[1,16,18,29,44],\n",
        "[9,28,30,43,49],\n",
        "[9,16,17,20,32],\n",
        "[1,10,25,39,44],\n",
        "[9,11,13,35,38],\n",
        "[3,26,31,33,50],\n",
        "[5,34,37,43,48],\n",
        "[1,18,26,40,47],\n",
        "[5,6,13,20,33],\n",
        "[4,17,27,33,46],\n",
        "[8,24,25,30,50],\n",
        "[19,31,32,40,46],\n",
        "[12,14,18,38,46],\n",
        "[8,23,24,39,50],\n",
        "[1,6,16,28,38],\n",
        "[19,38,40,41,50],\n",
        "[17,23,27,30,39],\n",
        "[12,14,20,21,39],\n",
        "[14,27,28,35,47],\n",
        "[1,31,40,41,45],\n",
        "[12,35,36,39,47],\n",
        "[6,21,30,37,44],\n",
        "[6,12,15,20,30],\n",
        "[11,19,24,46,49],\n",
        "[1,9,15,22,49],\n",
        "[1,7,27,28,41],\n",
        "[13,20,39,40,42],\n",
        "[5,8,33,34,46],\n",
        "[12,23,37,41,46],\n",
        "[7,22,27,30,31],\n",
        "[3,7,13,41,48],\n",
        "[3,5,13,16,30],\n",
        "[7,9,28,39,47],\n",
        "[13,14,23,26,31],\n",
        "[11,19,38,42,46],\n",
        "[16,18,34,36,49],\n",
        "[5,15,16,36,37],\n",
        "[2,4,8,22,24],\n",
        "[19,23,26,27,49],\n",
        "[1,18,20,31,36],\n",
        "[2,7,13,26,49],\n",
        "[14,16,26,34,38],\n",
        "[34,36,37,39,49],\n",
        "[11,19,27,32,42],\n",
        "[8,9,33,34,36],\n",
        "[11,14,35,44,45],\n",
        "[1,2,5,24,47],\n",
        "[4,23,25,37,39],\n",
        "[3,19,26,29,36],\n",
        "[3,20,32,40,42],\n",
        "[10,25,35,37,43],\n",
        "[7,20,21,33,41],\n",
        "[10,12,28,29,49],\n",
        "[9,11,19,42,45],\n",
        "[2,5,10,13,28],\n",
        "[10,16,31,37,40],\n",
        "[10,20,35,47,50],\n",
        "[9,10,19,20,35],\n",
        "[6,12,21,40,49],\n",
        "[1,2,16,31,50],\n",
        "[1,5,17,39,46],\n",
        "[5,28,31,33,49],\n",
        "[10,14,20,24,40],\n",
        "[12,24,38,45,46],\n",
        "[6,7,36,39,40],\n",
        "[6,19,23,33,34],\n",
        "[4,10,26,33,48],\n",
        "[13,20,32,34,47],\n",
        "[11,12,26,28,37],\n",
        "[16,18,19,23,44],\n",
        "[19,21,24,41,48],\n",
        "[29,37,38,47,50],\n",
        "[4,19,21,31,42],\n",
        "[12,22,36,38,50],\n",
        "[6,14,20,26,46],\n",
        "[4,8,22,36,44],\n",
        "[5,11,12,30,40],\n",
        "[6,15,18,21,38],\n",
        "[22,33,42,43,46],\n",
        "[4,8,9,33,43],\n",
        "[15,28,30,42,50],\n",
        "[11,27,34,35,39],\n",
        "[15,28,30,37,43],\n",
        "[1,7,23,25,45],\n",
        "[4,28,29,39,44],\n",
        "[1,10,20,43,44],\n",
        "[7,10,25,39,42],\n",
        "[14,16,28,34,35],\n",
        "[1,4,6,12,13],\n",
        "[14,15,16,22,50],\n",
        "[1,16,18,42,47],\n",
        "[7,10,16,32,40],\n",
        "[19,28,34,45,49],\n",
        "[1,20,39,48,50],\n",
        "[12,17,29,44,50],\n",
        "[2,3,24,25,34],\n",
        "[13,27,30,42,46],\n",
        "[27,30,45,47,50],\n",
        "[7,14,23,27,35],\n",
        "[2,21,26,44,45],\n",
        "[5,23,25,35,40],\n",
        "[12,15,19,29,48],\n",
        "[4,5,17,39,47],\n",
        "[13,23,31,42,44],\n",
        "[7,18,19,40,49],\n",
        "[1,7,13,19,20],\n",
        "[3,7,16,18,25],\n",
        "[13,18,20,35,46],\n",
        "[3,16,25,38,45],\n",
        "[25,26,30,36,44],\n",
        "[8,14,34,40,44],\n",
        "[10,27,43,45,46],\n",
        "[6,22,33,46,49],\n",
        "[27,31,44,46,49],\n",
        "[3,38,39,41,45],\n",
        "[8,11,23,41,42],\n",
        "[7,14,31,35,46],\n",
        "[22,33,41,46,50],\n",
        "[3,11,13,15,23],\n",
        "[2,4,17,20,46],\n",
        "[13,17,20,24,47],\n",
        "[1,24,25,31,38],\n",
        "[6,14,19,27,35],\n",
        "[1,3,11,18,31],\n",
        "[15,16,17,23,30],\n",
        "[3,9,25,31,49],\n",
        "[27,35,36,38,48],\n",
        "[14,18,26,40,45],\n",
        "[18,39,44,46,47],\n",
        "[13,14,21,23,40],\n",
        "[1,4,20,32,34],\n",
        "[11,20,28,41,45],\n",
        "[3,4,9,19,28],\n",
        "[11,38,40,42,48],\n",
        "[15,22,29,33,47],\n",
        "[10,17,32,36,47],\n",
        "[2,12,15,29,44],\n",
        "[5,17,28,40,44],\n",
        "[9,40,43,44,46],\n",
        "[1,10,25,46,49],\n",
        "[2,20,23,29,50],\n",
        "[2,35,44,45,50],\n",
        "[1,14,17,24,50],\n",
        "[3,4,17,41,47],\n",
        "[11,16,18,22,43],\n",
        "[5,16,20,29,30],\n",
        "[9,15,20,24,34],\n",
        "[1,7,12,16,18],\n",
        "[16,26,32,40,47],\n",
        "[16,30,33,40,43],\n",
        "[2,7,38,40,45],\n",
        "[16,17,25,40,44],\n",
        "[3,9,17,45,47],\n",
        "[10,23,26,29,35],\n",
        "[15,24,29,33,41],\n",
        "[7,8,24,34,46],\n",
        "[4,8,19,25,44],\n",
        "[18,26,33,42,46],\n",
        "[16,18,20,27,46],\n",
        "[15,23,28,33,36],\n",
        "[4,27,37,48,49],\n",
        "[4,14,22,33,42],\n",
        "[5,15,17,29,32],\n",
        "[6,8,16,23,50],\n",
        "[3,10,21,25,34],\n",
        "[22,24,25,28,46],\n",
        "[9,21,31,32,33],\n",
        "[24,26,29,36,49],\n",
        "[3,14,17,37,39],\n",
        "[1,11,23,41,44],\n",
        "[15,31,35,40,46],\n",
        "[14,19,21,30,32],\n",
        "[5,13,22,36,39],\n",
        "[1,5,7,9,21],\n",
        "[16,24,33,35,43],\n",
        "[9,18,30,47,48],\n",
        "[2,7,24,38,45],\n",
        "[13,14,21,34,46],\n",
        "[13,33,40,42,43],\n",
        "[2,22,40,43,50],\n",
        "[4,8,12,25,31],\n",
        "[4,15,17,21,23],\n",
        "[2,12,32,43,44],\n",
        "[8,25,26,38,48],\n",
        "[3,6,9,18,24],\n",
        "[4,7,28,36,43],\n",
        "[24,33,35,46,49],\n",
        "[5,8,16,42,46],\n",
        "[3,8,13,18,40],\n",
        "[12,15,32,44,49],\n",
        "[6,26,31,42,50],\n",
        "[9,12,28,32,48],\n",
        "[18,19,33,38,44],\n",
        "[5,17,27,33,42],\n",
        "[8,32,34,46,49],\n",
        "[13,15,18,39,45],\n",
        "[17,22,28,31,46],\n",
        "[18,22,35,36,41],\n",
        "[4,16,21,31,42],\n",
        "[4,14,24,26,30],\n",
        "[3,16,20,34,49],\n",
        "[19,24,31,38,40],\n",
        "[3,10,25,32,43],\n",
        "[6,12,35,39,49],\n",
        "[2,9,23,36,47],\n",
        "[24,25,28,35,48],\n",
        "[6,29,38,45,47],\n",
        "[5,8,21,24,26],\n",
        "[1,24,30,31,47],\n",
        "[14,16,21,25,26],\n",
        "[7,16,18,19,24],\n",
        "[4,29,30,31,45],\n",
        "[1,2,11,19,47],\n",
        "[15,20,24,44,49],\n",
        "[4,9,15,24,42],\n",
        "[22,31,43,44,50],\n",
        "[14,16,21,30,37],\n",
        "[18,21,37,43,47],\n",
        "[1,6,11,17,38],\n",
        "[3,9,10,19,42],\n",
        "[5,7,15,19,29],\n",
        "[20,27,33,35,46],\n",
        "[8,26,38,47,50],\n",
        "[10,12,35,36,43],\n",
        "[7,8,20,35,38],\n",
        "[8,23,40,41,42],\n",
        "[20,27,37,41,45],\n",
        "[18,25,26,35,38],\n",
        "[1,15,34,48,50],\n",
        "[31,36,40,42,45],\n",
        "[31,32,45,47,49],\n",
        "[3,8,30,46,48],\n",
        "[6,11,38,41,44],\n",
        "[2,4,20,21,49],\n",
        "[7,20,35,42,44],\n",
        "[15,18,19,41,42],\n",
        "[10,18,32,35,46],\n",
        "[21,24,29,30,50],\n",
        "[3,21,22,33,47],\n",
        "[17,21,41,48,49],\n",
        "[21,24,26,34,47],\n",
        "[15,19,20,45,49],\n",
        "[8,12,13,39,44],\n",
        "[6,9,31,43,44],\n",
        "[2,30,34,35,45],\n",
        "[3,17,31,34,40],\n",
        "[14,20,23,39,49],\n",
        "[10,19,24,30,39],\n",
        "[3,12,24,37,38],\n",
        "[2,3,30,31,45],\n",
        "[8,14,23,30,45],\n",
        "[25,31,38,49,50],\n",
        "[12,20,21,22,35],\n",
        "[7,12,28,34,45],\n",
        "[6,27,30,35,41],\n",
        "[4,14,25,34,49],\n",
        "[1,23,32,45,49],\n",
        "[5,12,20,29,48],\n",
        "[1,7,12,23,39],\n",
        "[7,16,22,36,44],\n",
        "[2,6,30,32,49],\n",
        "[2,13,39,45,47],\n",
        "[12,22,24,29,38],\n",
        "[15,19,35,36,41],\n",
        "[1,17,29,39,42],\n",
        "[9,14,28,30,37],\n",
        "[13,19,23,34,41],\n",
        "[3,21,26,40,41],\n",
        "[2,7,8,43,50],\n",
        "[1,18,23,33,41],\n",
        "[6,13,15,34,35],\n",
        "[6,11,12,21,41],\n",
        "[9,11,15,36,43],\n",
        "[21,27,29,34,49],\n",
        "[12,15,32,40,45],\n",
        "[8,22,31,32,36],\n",
        "[9,16,17,29,39],\n",
        "[7,16,22,30,48],\n",
        "[2,22,33,38,47],\n",
        "[14,16,32,34,47],\n",
        "[12,34,36,47,48],\n",
        "[5,6,9,15,29],\n",
        "[13,21,25,34,35],\n",
        "[7,11,19,32,43],\n",
        "[3,19,28,43,49],\n",
        "[4,9,15,24,28],\n",
        "[9,20,27,35,48],\n",
        "[26,27,30,46,49],\n",
        "[8,11,22,38,41],\n",
        "[5,23,28,38,49],\n",
        "[2,5,24,43,45],\n",
        "[7,12,14,40,42],\n",
        "[1,7,9,29,46],\n",
        "[15,19,34,39,49],\n",
        "[1,11,17,23,29],\n",
        "[5,11,35,44,50],\n",
        "[17,21,23,37,45],\n",
        "[11,19,24,33,39],\n",
        "[5,12,26,47,50],\n",
        "[5,17,21,37,38],\n",
        "[18,20,34,49,50],\n",
        "[1,2,22,25,30],\n",
        "[1,27,37,40,41],\n",
        "[4,13,15,41,49],\n",
        "[4,17,27,28,50],\n",
        "[7,10,19,26,42],\n",
        "[17,36,38,43,46],\n",
        "[8,22,25,38,50],\n",
        "[10,19,32,36,46],\n",
        "[38,40,41,46,48],\n",
        "[16,30,33,36,43],\n",
        "[2,3,16,33,46],\n",
        "[15,18,24,27,44],\n",
        "[27,35,36,38,41],\n",
        "[3,13,24,29,32],\n",
        "[9,23,34,40,42],\n",
        "[6,11,18,26,34],\n",
        "[3,11,19,34,37],\n",
        "[7,38,41,44,50],\n",
        "[1,3,4,36,43],\n",
        "[11,18,23,29,32],\n",
        "[12,19,20,28,31],\n",
        "[3,6,11,14,49],\n",
        "[23,27,34,40,43],\n",
        "[3,7,19,27,29],\n",
        "[1,15,29,42,50],\n",
        "[2,12,15,33,39],\n",
        "[15,26,35,37,43],\n",
        "[13,17,26,49,50],\n",
        "[8,20,23,48,50],\n",
        "[11,14,44,46,49],\n",
        "[4,17,22,30,47],\n",
        "[4,5,10,25,31],\n",
        "[8,14,15,20,31],\n",
        "[9,14,24,37,39],\n",
        "[13,33,42,48,50],\n",
        "[5,14,39,43,44],\n",
        "[16,19,21,29,36],\n",
        "[4,31,39,43,46],\n",
        "[8,31,34,36,45],\n",
        "[19,20,22,25,42],\n",
        "[5,9,20,44,48],\n",
        "[2,14,18,23,42],\n",
        "[14,17,20,27,32],\n",
        "[12,22,35,38,49],\n",
        "[20,33,34,37,39],\n",
        "[20,28,32,38,46],\n",
        "[2,6,8,21,25],\n",
        "[15,33,34,38,43],\n",
        "[11,23,37,38,44],\n",
        "[6,13,25,31,49],\n",
        "[4,30,43,44,46],\n",
        "[6,12,20,21,34],\n",
        "[7,17,21,37,39],\n",
        "[2,5,13,15,23],\n",
        "[8,9,30,34,48],\n",
        "[6,8,16,44,50],\n",
        "[3,17,21,35,42],\n",
        "[7,16,36,42,43],\n",
        "[8,17,21,23,47],\n",
        "[9,15,27,41,44],\n",
        "[2,5,9,29,32],\n",
        "[5,21,23,29,35],\n",
        "[12,18,27,33,41],\n",
        "[5,10,26,37,42],\n",
        "[5,10,25,29,32],\n",
        "[4,19,34,41,43],\n",
        "[1,17,20,36,49],\n",
        "[5,31,39,46,49],\n",
        "[1,8,33,38,43],\n",
        "[11,20,31,35,46],\n",
        "[10,15,18,24,39],\n",
        "[7,8,35,37,49],\n",
        "[9,10,28,38,48],\n",
        "[2,26,41,45,48],\n",
        "[19,20,24,36,41],\n",
        "[2,5,10,20,24],\n",
        "[3,7,15,17,35],\n",
        "[2,18,28,42,50],\n",
        "[10,27,32,41,49],\n",
        "[5,6,17,18,34],\n",
        "[6,13,22,24,30],\n",
        "[5,6,39,49,50],\n",
        "[3,7,34,43,50],\n",
        "[7,13,30,43,47],\n",
        "[2,13,41,45,50],\n",
        "[4,22,28,32,47],\n",
        "[25,26,40,45,47],\n",
        "[8,26,29,41,48],\n",
        "[14,30,37,39,50],\n",
        "[4,22,27,39,41],\n",
        "[5,7,45,48,49],\n",
        "[3,21,23,28,46],\n",
        "[11,28,30,35,50],\n",
        "[1,2,23,43,45],\n",
        "[6,10,17,29,49],\n",
        "[13,24,30,35,48],\n",
        "[2,10,23,29,50],\n",
        "[4,10,24,34,35],\n",
        "[7,16,28,36,43],\n",
        "[6,10,22,30,36],\n",
        "[3,16,26,30,47],\n",
        "[9,11,16,19,32],\n",
        "[20,23,24,37,43],\n",
        "[1,11,17,19,33],\n",
        "[1,2,7,24,25],\n",
        "[14,26,29,46,50],\n",
        "[6,11,39,40,47],\n",
        "[10,12,17,31,49],\n",
        "[23,26,36,40,44],\n",
        "[14,32,34,38,46],\n",
        "[4,17,32,34,49],\n",
        "[4,13,32,39,41],\n",
        "[2,9,18,21,39],\n",
        "[2,6,18,29,37],\n",
        "[18,27,41,45,49],\n",
        "[2,5,11,22,24],\n",
        "[6,10,11,20,38],\n",
        "[9,18,26,41,43],\n",
        "[20,22,26,34,40],\n",
        "[16,25,27,41,45],\n",
        "[2,13,22,36,40],\n",
        "[20,30,38,39,44],\n",
        "[15,23,26,31,44],\n",
        "[8,12,15,17,46],\n",
        "[17,42,43,48,49],\n",
        "[16,17,26,30,35],\n",
        "[7,35,36,39,47],\n",
        "[3,5,8,10,44],\n",
        "[13,18,24,34,50],\n",
        "[2,11,18,47,49],\n",
        "[17,26,35,37,39],\n",
        "[4,5,21,30,43],\n",
        "[18,32,39,42,44],\n",
        "[7,9,40,48,49],\n",
        "[15,17,23,35,38],\n",
        "[11,15,24,28,41],\n",
        "[1,7,11,33,48],\n",
        "[13,14,25,28,42],\n",
        "[11,20,23,37,46],\n",
        "[4,6,8,42,48],\n",
        "[9,16,32,37,46],\n",
        "[6,12,25,48,49],\n",
        "[8,12,37,44,47],\n",
        "[6,8,13,21,32],\n",
        "[3,13,33,36,47],\n",
        "[9,14,15,20,47],\n",
        "[6,11,26,43,49],\n",
        "[9,34,35,42,44],\n",
        "[28,33,34,37,44],\n",
        "[3,37,45,47,50],\n",
        "[28,29,31,37,50],\n",
        "[14,28,31,47,50],\n",
        "[9,16,27,41,45],\n",
        "[7,14,34,41,49],\n",
        "[6,11,16,35,44],\n",
        "[1,12,15,31,47],\n",
        "[9,16,17,27,31],\n",
        "[4,9,29,34,37],\n",
        "[20,21,30,41,43],\n",
        "[1,7,17,44,50],\n",
        "[10,15,25,37,46],\n",
        "[3,10,20,36,42],\n",
        "[1,2,6,14,45],\n",
        "[5,12,15,21,39],\n",
        "[13,20,34,38,43],\n",
        "[1,5,12,18,20],\n",
        "[6,20,27,38,49],\n",
        "[1,18,37,46,48],\n",
        "[4,11,12,16,42],\n",
        "[6,17,22,39,46],\n",
        "[9,16,32,34,48],\n",
        "[5,18,21,29,45],\n",
        "[8,13,16,44,47],\n",
        "[6,21,23,26,43],\n",
        "[6,12,36,37,44],\n",
        "[10,11,31,37,44],\n",
        "[1,15,19,24,33],\n",
        "[16,28,32,36,48],\n",
        "[5,19,33,37,42],\n",
        "[7,11,20,21,29],\n",
        "[16,28,31,35,42],\n",
        "[5,13,16,41,45],\n",
        "[12,21,24,28,40],\n",
        "[4,8,9,30,35],\n",
        "[11,12,13,23,26],\n",
        "[17,18,30,33,35],\n",
        "[6,11,29,34,39],\n",
        "[10,27,30,32,34],\n",
        "[28,30,31,45,46],\n",
        "[1,5,8,20,35],\n",
        "[1,2,11,14,36],\n",
        "[1,3,29,45,47],\n",
        "[2,8,16,21,39],\n",
        "[8,9,11,13,50],\n",
        "[5,7,21,22,29],\n",
        "[8,13,24,35,46],\n",
        "[11,29,32,46,47],\n",
        "[5,19,33,36,42],\n",
        "[9,18,30,34,48],\n",
        "[2,3,18,23,39],\n",
        "[7,10,13,34,47],\n",
        "[3,14,23,41,43],\n",
        "[19,21,23,36,39],\n",
        "[9,18,20,40,41],\n",
        "[11,15,17,24,46],\n",
        "[2,4,12,31,50],\n",
        "[14,16,24,40,43],\n",
        "[7,16,22,38,41],\n",
        "[3,9,11,20,39],\n",
        "[10,16,34,36,49],\n",
        "[2,9,38,40,44],\n",
        "[3,17,19,32,38],\n",
        "[6,12,25,31,37],\n",
        "[1,35,36,38,39],\n",
        "[12,21,23,26,41],\n",
        "[2,16,22,28,46],\n",
        "[8,40,41,46,47],\n",
        "[2,5,11,27,38],\n",
        "[14,18,20,39,42],\n",
        "[1,13,16,23,27],\n",
        "[9,11,13,15,25],\n",
        "[21,29,31,46,49],\n",
        "[5,13,43,45,50],\n",
        "[3,8,10,31,36],\n",
        "[8,18,26,38,39],\n",
        "[14,24,31,44,45],\n",
        "[23,24,38,42,44],\n",
        "[14,24,29,45,48],\n",
        "[13,28,29,31,47],\n",
        "[17,18,40,43,50],\n",
        "[7,8,12,21,43],\n",
        "[16,23,30,37,41],\n",
        "[6,8,42,49,50],\n",
        "[11,16,22,34,46],\n",
        "[5,14,35,40,47],\n",
        "[6,13,15,20,40],\n",
        "[6,15,21,34,48],\n",
        "[6,21,23,31,39],\n",
        "[26,36,43,47,49],\n",
        "[1,17,22,29,31],\n",
        "[9,30,34,38,48],\n",
        "[4,14,15,20,28],\n",
        "[9,20,21,22,38],\n",
        "[16,27,33,34,39],\n",
        "[11,12,13,23,36],\n",
        "[23,32,38,45,49],\n",
        "[6,11,16,26,49],\n",
        "[2,8,28,32,37],\n",
        "[2,8,20,34,40],\n",
        "[7,15,17,18,39],\n",
        "[4,6,17,31,45],\n",
        "[4,6,12,31,38],\n",
        "[4,13,16,22,27],\n",
        "[2,21,34,40,48],\n",
        "[19,26,36,48,49],\n",
        "[11,30,32,45,47],\n",
        "[9,12,26,41,47],\n",
        "[3,31,34,43,45],\n",
        "[6,19,32,39,42],\n",
        "[10,12,18,33,47],\n",
        "[9,18,20,32,39],\n",
        "[18,23,35,37,41],\n",
        "[10,12,15,46,48],\n",
        "[13,17,21,30,39],\n",
        "[16,19,20,26,44],\n",
        "[4,10,11,20,22],\n",
        "[7,20,22,45,48],\n",
        "[7,11,17,18,34],\n",
        "[1,3,11,15,30],\n",
        "[10,19,22,37,41],\n",
        "[15,17,30,38,49],\n",
        "[13,26,30,34,41],\n",
        "[2,20,30,31,40],\n",
        "[2,11,17,23,49],\n",
        "[2,8,11,16,20],\n",
        "[16,20,25,30,49],\n",
        "[1,20,28,32,49],\n",
        "[5,17,36,37,50],\n",
        "[12,15,17,30,32],\n",
        "[7,11,30,31,39],\n",
        "[14,17,29,32,45],\n",
        "[5,8,16,30,37],\n",
        "[1,7,21,27,43],\n",
        "[1,34,39,47,49],\n",
        "[35,36,37,41,48],\n",
        "[8,14,21,34,36],\n",
        "[2,3,6,15,35],\n",
        "[3,18,23,29,47],\n",
        "[4,20,33,37,45],\n",
        "[9,17,36,40,45],\n",
        "[3,11,32,33,35],\n",
        "[28,31,39,45,49],\n",
        "[19,22,23,24,27],\n",
        "[1,2,29,36,48],\n",
        "[7,23,31,33,38],\n",
        "[2,3,4,21,45],\n",
        "[13,26,27,35,46],\n",
        "[4,23,34,39,45],\n",
        "[1,3,24,43,49],\n",
        "[8,15,29,37,45],\n",
        "[4,12,16,29,31],\n",
        "[10,21,27,42,46],\n",
        "[4,10,23,24,45],\n",
        "[2,22,24,30,40],\n",
        "[8,14,25,31,45],\n",
        "[1,8,30,43,45],\n",
        "[10,29,30,32,40],\n",
        "[4,11,16,25,32],\n",
        "[5,14,25,26,44],\n",
        "[2,14,30,32,34],\n",
        "[8,22,27,36,43],\n",
        "[13,18,22,26,32],\n",
        "[9,13,21,24,38],\n",
        "[7,11,22,26,46],\n",
        "[2,16,30,31,49],\n",
        "[14,20,26,30,31],\n",
        "[4,9,22,32,35],\n",
        "[15,18,25,29,35],\n",
        "[6,9,33,34,50],\n",
        "[4,11,16,46,50],\n",
        "[25,28,29,31,33],\n",
        "[13,21,22,26,48],\n",
        "[15,24,29,33,39],\n",
        "[8,11,25,31,48],\n",
        "[5,17,23,36,37],\n",
        "[7,11,27,42,45],\n",
        "[7,10,31,41,46],\n",
        "[2,3,17,40,44],\n",
        "[1,3,13,24,44],\n",
        "[9,17,19,26,39],\n",
        "[3,13,34,41,43],\n",
        "[6,15,25,29,41],\n",
        "[17,37,42,45,50],\n",
        "[4,16,27,34,44],\n",
        "[13,29,42,44,48],\n",
        "[8,11,23,44,45],\n",
        "[9,20,38,44,45],\n",
        "[2,4,23,30,40],\n",
        "[4,32,36,38,47],\n",
        "[2,19,36,42,50],\n",
        "[3,17,26,30,49],\n",
        "[13,21,27,28,41],\n",
        "[22,29,36,38,43],\n",
        "[6,23,38,42,45],\n",
        "[2,3,34,38,49],\n",
        "[27,31,35,46,50],\n",
        "[4,7,19,26,27],\n",
        "[6,10,30,34,41],\n",
        "[20,21,28,32,37],\n",
        "[10,19,24,25,40],\n",
        "[7,20,23,24,37],\n",
        "[8,14,45,47,50],\n",
        "[17,23,30,41,43],\n",
        "[1,4,19,35,42],\n",
        "[11,14,18,35,42],\n",
        "[1,3,10,32,44],\n",
        "[9,15,28,36,39],\n",
        "[9,15,28,36,39],\n",
        "[1,9,25,27,37],\n",
        "[2,21,26,34,49],\n",
        "[1,20,21,27,29],\n",
        "[1,16,20,23,44],\n",
        "[17,34,38,42,48]\n",
        "]\n",
        "data = pd.DataFrame(data_content, columns=range(5))\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Parametry modelu\n",
        "input_dim = X_scaled.shape[1]\n",
        "latent_dim = 12\n",
        "num_mixtures = 5\n",
        "\n",
        "# Funkcja straty MDN\n",
        "def mdn_loss(num_mixtures, output_dim):\n",
        "    def loss(y_true, outputs):\n",
        "        alphas, mus, sigmas = tf.split(outputs, [\n",
        "            num_mixtures, num_mixtures * output_dim, num_mixtures * output_dim\n",
        "        ], axis=-1)\n",
        "        mus = tf.reshape(mus, [-1, num_mixtures, output_dim])\n",
        "        sigmas = tf.reshape(sigmas, [-1, num_mixtures, output_dim])\n",
        "        y_true = tf.expand_dims(y_true, axis=1)\n",
        "\n",
        "        gaussians = tf.exp(\n",
        "            -0.5 * tf.reduce_sum(tf.square(\n",
        "                (y_true - mus) / sigmas), axis=-1)) / (\n",
        "                    tf.reduce_prod(sigmas, axis=-1) * tf.sqrt(2.0 * np.pi))\n",
        "        weighted_gaussians = alphas * gaussians\n",
        "        nll = -tf.math.log(tf.reduce_sum(weighted_gaussians, axis=-1) + 1e-8)\n",
        "        return tf.reduce_mean(nll)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Tworzenie modelu MDN + VAE\n",
        "def create_mdn_vae_model(input_dim, latent_dim, num_mixtures):\n",
        "    inputs = Input(shape=(input_dim, ))\n",
        "    h = Dense(64, activation='relu')(inputs)\n",
        "    h = Dense(32, activation='relu')(h)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim, ),\n",
        "               name='z')([z_mean, z_log_var])\n",
        "\n",
        "    h_decoder = Dense(32, activation='relu')(z)\n",
        "    h_decoder = Dense(64, activation='relu')(h_decoder)\n",
        "\n",
        "    alphas = Dense(num_mixtures, activation='softmax',\n",
        "                   name='alphas')(h_decoder)\n",
        "    mus = Dense(num_mixtures * input_dim, name='mus')(h_decoder)\n",
        "    sigmas = Dense(num_mixtures * input_dim,\n",
        "                   activation='softplus',\n",
        "                   name='sigmas')(h_decoder)\n",
        "\n",
        "    outputs = Lambda(lambda x: tf.concat(x, axis=-1),\n",
        "                     name='mdn_output')([alphas, mus, sigmas])\n",
        "\n",
        "    mdn_vae = Model(inputs, outputs, name='mdn_vae')\n",
        "    return mdn_vae\n",
        "\n",
        "# Kompilacja modelu\n",
        "model = create_mdn_vae_model(input_dim, latent_dim, num_mixtures)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=mdn_loss(num_mixtures, input_dim))\n",
        "\n",
        "# Trening\n",
        "model.fit(X_scaled, X_scaled, epochs=iRow, batch_size=100, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Funkcja oceny próbki\n",
        "def evaluate_sample(model, scaler, sample, target_pattern):\n",
        "    output = model.predict(sample, verbose=0)\n",
        "    alphas, mus, sigmas = tf.split(output, [\n",
        "        num_mixtures, num_mixtures * input_dim,\n",
        "        num_mixtures * input_dim\n",
        "    ], axis=-1)\n",
        "\n",
        "    mus = tf.reshape(mus, [-1, num_mixtures, input_dim])\n",
        "    prediction = scaler.inverse_transform(tf.reshape(mus[0, 0, :], (1, -1)).numpy())\n",
        "    generated_numbers = sorted(np.round(np.clip(prediction[0], 1, 50)).astype(int))\n",
        "\n",
        "    # Dopasowanie liczby elementów w generated_numbers do target_pattern\n",
        "    if len(generated_numbers) > len(target_pattern):\n",
        "        generated_numbers = generated_numbers[:len(target_pattern)]  # Przycięcie\n",
        "    elif len(generated_numbers) < len(target_pattern):\n",
        "        generated_numbers += [0] * (len(target_pattern) - len(generated_numbers))  # Uzupełnienie zerami\n",
        "\n",
        "    score = np.sum(np.abs(np.array(generated_numbers) - np.array(target_pattern)))\n",
        "    return -score\n",
        "\n",
        "# Algorytm Metropolisa-Hastingsa\n",
        "def metropolis_hastings(model, scaler, target_pattern, num_samples=iRow, input_dim=5):\n",
        "    current_sample = np.random.normal(size=(1, input_dim))\n",
        "    accepted_samples = []\n",
        "    current_score = evaluate_sample(model, scaler, current_sample, target_pattern)\n",
        "\n",
        "    with tqdm(total=num_samples, desc=\"MCMC Progress\", unit=\"sample\") as pbar:\n",
        "        for _ in range(num_samples):\n",
        "            proposed_sample = current_sample + np.random.normal(0, 0.1, size=current_sample.shape)\n",
        "            proposed_score = evaluate_sample(model, scaler, proposed_sample, target_pattern)\n",
        "            acceptance_prob = min(1, np.exp(current_score - proposed_score))\n",
        "\n",
        "            if np.random.rand() < acceptance_prob:\n",
        "                current_sample = proposed_sample\n",
        "                current_score = proposed_score\n",
        "                accepted_samples.append(current_sample)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return np.array(accepted_samples)\n",
        "\n",
        "# Szukanie wzorca za pomocą MCMC\n",
        "# def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=1_000_000):\n",
        "def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=iRow):\n",
        "    print(f\"Rozpoczynam wyszukiwanie wzorca {target_pattern} przy użyciu MCMC...\")\n",
        "\n",
        "    accepted_samples = metropolis_hastings(model, scaler, target_pattern, num_samples=max_samples)\n",
        "\n",
        "    for sample in accepted_samples:\n",
        "        generated_numbers = sorted(np.round(np.clip(sample[0], 1, 50)).astype(int))\n",
        "        if generated_numbers == target_pattern:\n",
        "            print(f\"\\nZnaleziono wzorzec: {generated_numbers}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"\\nNie znaleziono wzorca w wygenerowanych próbkach.\")\n",
        "\n",
        "print(f\"Szukanie wzorca dla seeda1: {seed1_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)\n",
        "\n",
        "print(f\"\\nSzukanie wzorca dla seeda2: {seed2_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8gokSirsTL07",
        "outputId": "8daa55e0-d317-4e4b-f871-5c72d0db8120"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4370 - val_loss: -1.1544\n",
            "Epoch 2/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.4285 - val_loss: -2.6255\n",
            "Epoch 3/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -2.7700 - val_loss: -3.3775\n",
            "Epoch 4/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -3.1922 - val_loss: -3.9434\n",
            "Epoch 5/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -3.7505 - val_loss: -3.9908\n",
            "Epoch 6/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -4.0784 - val_loss: -4.4802\n",
            "Epoch 7/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -4.5645 - val_loss: -5.4699\n",
            "Epoch 8/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -5.4757 - val_loss: -5.9257\n",
            "Epoch 9/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -6.0110 - val_loss: -6.5122\n",
            "Epoch 10/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -6.0939 - val_loss: -6.6463\n",
            "Epoch 11/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -6.6123 - val_loss: -7.1630\n",
            "Epoch 12/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -6.7848 - val_loss: -7.3561\n",
            "Epoch 13/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -7.3736 - val_loss: -7.7419\n",
            "Epoch 14/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -7.6475 - val_loss: -8.3669\n",
            "Epoch 15/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.0433 - val_loss: -8.2161\n",
            "Epoch 16/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.1322 - val_loss: -8.5836\n",
            "Epoch 17/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.3099 - val_loss: -8.4439\n",
            "Epoch 18/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.2552 - val_loss: -8.5204\n",
            "Epoch 19/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.4658 - val_loss: -8.4547\n",
            "Epoch 20/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.4737 - val_loss: -8.5880\n",
            "Epoch 21/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -8.6798 - val_loss: -8.5792\n",
            "Epoch 22/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -8.5965 - val_loss: -8.8913\n",
            "Epoch 23/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -8.8485 - val_loss: -9.0866\n",
            "Epoch 24/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -8.7433 - val_loss: -9.0543\n",
            "Epoch 25/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -9.1388 - val_loss: -9.5341\n",
            "Epoch 26/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -8.8349 - val_loss: -9.3983\n",
            "Epoch 27/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -9.5247 - val_loss: -9.8620\n",
            "Epoch 28/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -9.8070 - val_loss: -10.0402\n",
            "Epoch 29/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -9.8064 - val_loss: -10.3191\n",
            "Epoch 30/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -10.4125 - val_loss: -9.2371\n",
            "Epoch 31/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -9.3419 - val_loss: -10.9058\n",
            "Epoch 32/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -9.9120 - val_loss: -10.9330\n",
            "Epoch 33/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -11.0080 - val_loss: -11.4308\n",
            "Epoch 34/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -11.5971 - val_loss: -9.1503\n",
            "Epoch 35/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -7.7381 - val_loss: -10.9692\n",
            "Epoch 36/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -11.1130 - val_loss: -11.1565\n",
            "Epoch 37/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -9.6464 - val_loss: -11.4521\n",
            "Epoch 38/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -11.9534 - val_loss: -12.2453\n",
            "Epoch 39/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -12.3260 - val_loss: -13.1961\n",
            "Epoch 40/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -11.3358 - val_loss: -12.9369\n",
            "Epoch 41/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -12.1329 - val_loss: -11.9507\n",
            "Epoch 42/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -12.0455 - val_loss: -10.4628\n",
            "Epoch 43/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -11.8609 - val_loss: -14.0294\n",
            "Epoch 44/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -10.1011 - val_loss: -12.5761\n",
            "Epoch 45/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -13.2697 - val_loss: -14.3506\n",
            "Epoch 46/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -14.2799 - val_loss: -15.3470\n",
            "Epoch 47/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -14.1108 - val_loss: -14.7571\n",
            "Epoch 48/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -14.5672 - val_loss: -15.0501\n",
            "Epoch 49/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -14.8228 - val_loss: -12.7394\n",
            "Epoch 50/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -14.4370 - val_loss: -16.0494\n",
            "Epoch 51/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -15.3249 - val_loss: -2.8159\n",
            "Epoch 52/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -7.3492 - val_loss: -14.1724\n",
            "Epoch 53/7500000\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -14.4348 - val_loss: -0.9624\n",
            "Epoch 54/7500000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-364c89f74c49>\u001b[0m in \u001b[0;36m<cell line: 918>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;31m# Trening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;31m# Funkcja oceny próbki\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36menumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 for step in range(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ_JecKga2p"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://quantumai.google/cirq/start/start\"><img src=\"https://quantumai.google/site-assets/images/buttons/quantumai_logo_1x.png\" />View on QuantumAI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/colab_logo_1x.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/github_logo_1x.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/Cirq/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/download_icon_1x.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    import cirq\n",
        "\n",
        "    print(\"installed cirq.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4GQUN8MS7vt"
      },
      "outputs": [],
      "source": [
        "# Pick a qubit.\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Create a circuit that applies a square root of NOT gate, then measures the qubit.\n",
        "circuit = cirq.Circuit(cirq.X(qubit) ** 0.5, cirq.measure(qubit, key='m'))\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit several times.\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=20)\n",
        "print(\"Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNBShuQTFuu"
      },
      "source": [
        "# Congratulations\n",
        "You've just run your first Cirq program.\n",
        "\n",
        "To learn about running a circuit on a virtual machine that mimics existing quantum hardware, see [Quantum Virtual Machine](../simulate/quantum_virtual_machine.ipynb).\n",
        "\n",
        "If you would like to learn more about quantum computing, check out our [education page](https://quantumai.google/resources). The Full API reference for Cirq can be found [here](/reference/python/cirq). If you are looking for vendor specific information that can be found on our vendor sub-pages:\n",
        "\n",
        "\n",
        "  [Alpine Quantum Technologies](../hardware/aqt/getting_started.ipynb)\n",
        "  \n",
        "  [Pasqal](../hardware/pasqal/getting_started.ipynb)\n",
        "  \n",
        "  [IonQ](../hardware/ionq/getting_started.ipynb)\n",
        "  \n",
        "  [Azure](../hardware/azure-quantum/getting_started_honeywell.ipynb)\n",
        "  \n",
        "  [Rigetti](../hardware/rigetti/getting_started.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}