{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXhctqjgXO7"
      },
      "source": [
        "##### Copyright 2022 The Cirq Developers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RJVa8qgXou"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm  # Dodano do dynamicznego wyświetlania postępu\n",
        "\n",
        "# Ustawienia liczby rdzeni CPU dla TensorFlow\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(100)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(100)\n",
        "\n",
        "# Ustawienia seedów\n",
        "seed1_datetime = datetime.strptime(\"2024-11-26 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 20 21 28 32 37 . 01 04\n",
        "seed2_datetime = datetime.strptime(\"2024-12-03 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 07 20 23 24 37 . 04 10\n",
        "\n",
        "seed1 = int(seed1_datetime.timestamp())\n",
        "seed2 = int(seed2_datetime.timestamp())\n",
        "\n",
        "# Ustawienie seedów dla powtarzalności wyników\n",
        "np.random.seed(seed1)\n",
        "tf.random.set_seed(seed1)\n",
        "\n",
        "# Definiowanie target pattern dla \"2024-11-26\"\n",
        "target_pattern = [1, 4, 12]\n",
        "\n",
        "# [3-12] Parametry generowania\n",
        "rows_3_12          = 4_000_000         # Liczba wierszy (do ustalenia)\n",
        "cols_3_12          = 3              # Liczba kolumn dla 1-12\n",
        "number_range_12    = range(1, 13)   # Zakres liczb od 1 do 12\n",
        "excluded_values_12 = target_pattern # Liczby do wykluczenia\n",
        "\n",
        "def generate_2d_array(rows, cols, number_range, excluded_values=None):\n",
        "    \"\"\" Generuje dwuwymiarową tablicę danych o podanych wymiarach. \"\"\"\n",
        "    if excluded_values is None:\n",
        "        excluded_values = []\n",
        "\n",
        "    # Tworzenie listy dostępnych liczb\n",
        "    available_numbers = [num for num in number_range if num not in excluded_values]\n",
        "\n",
        "    if len(available_numbers) < cols:\n",
        "        raise ValueError(\"Za mało dostępnych liczb do wygenerowania unikalnych kolumn.\")\n",
        "\n",
        "    # Generowanie danych\n",
        "    data = [\n",
        "        sorted(random.sample(available_numbers, cols))  # Generuje unikalne, sortowane rosnąco wartości w każdym wierszu\n",
        "        for _ in range(rows) ]\n",
        "\n",
        "    return np.array(data)\n",
        "\n",
        "# Generowanie tablicy\n",
        "data = generate_2d_array(rows_3_12, cols_3_12, number_range_12, excluded_values_12)\n",
        "print(data)\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Parametry modelu\n",
        "input_dim = X_scaled.shape[1]\n",
        "latent_dim = 12\n",
        "num_mixtures = 3\n",
        "\n",
        "# Funkcja straty MDN (Mixture Density Network)\n",
        "def mdn_loss(num_mixtures, output_dim):\n",
        "    def loss(y_true, outputs):\n",
        "        alphas, mus, sigmas = tf.split(outputs, [\n",
        "            num_mixtures, num_mixtures * output_dim, num_mixtures * output_dim\n",
        "        ],\n",
        "                                       axis=-1)\n",
        "        mus = tf.reshape(mus, [-1, num_mixtures, output_dim])\n",
        "        sigmas = tf.reshape(sigmas, [-1, num_mixtures, output_dim])\n",
        "        y_true = tf.expand_dims(y_true, axis=1)\n",
        "\n",
        "        gaussians = tf.exp(\n",
        "            -0.5 * tf.reduce_sum(tf.square(\n",
        "                (y_true - mus) / sigmas), axis=-1)) / (\n",
        "                    tf.reduce_prod(sigmas, axis=-1) * tf.sqrt(2.0 * np.pi))\n",
        "        weighted_gaussians = alphas * gaussians\n",
        "        nll = -tf.math.log(tf.reduce_sum(weighted_gaussians, axis=-1) + 1e-8)\n",
        "        return tf.reduce_mean(nll)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Funkcja tworząca model MDN + VAE\n",
        "def create_mdn_vae_model(input_dim, latent_dim, num_mixtures):\n",
        "    inputs = Input(shape=(input_dim, ))\n",
        "    h = Dense(64, activation='relu')(inputs)\n",
        "    h = Dense(32, activation='relu')(h)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim, ),\n",
        "               name='z')([z_mean, z_log_var])\n",
        "\n",
        "    h_decoder = Dense(32, activation='relu')(z)\n",
        "    h_decoder = Dense(64, activation='relu')(h_decoder)\n",
        "\n",
        "    alphas = Dense(num_mixtures, activation='softmax',\n",
        "                   name='alphas')(h_decoder)\n",
        "    mus = Dense(num_mixtures * input_dim, name='mus')(h_decoder)\n",
        "    sigmas = Dense(num_mixtures * input_dim,\n",
        "                   activation='softplus',\n",
        "                   name='sigmas')(h_decoder)\n",
        "\n",
        "    outputs = Lambda(lambda x: tf.concat(x, axis=-1),\n",
        "                     name='mdn_output')([alphas, mus, sigmas])\n",
        "\n",
        "    mdn_vae = Model(inputs, outputs, name='mdn_vae')\n",
        "    return mdn_vae\n",
        "\n",
        "# Tworzenie i kompilacja modelu\n",
        "model = create_mdn_vae_model(input_dim, latent_dim, num_mixtures)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=mdn_loss(num_mixtures, input_dim))\n",
        "\n",
        "# Trening\n",
        "model.fit(X_scaled,\n",
        "          X_scaled,\n",
        "          epochs=1000,\n",
        "          batch_size=1000,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)\n",
        "\n",
        "# Funkcja do oceny próbki (używana w MCMC)\n",
        "def evaluate_sample(model, scaler, sample, target_pattern):\n",
        "    output = model.predict(sample, verbose=0)\n",
        "    alphas, mus, sigmas = tf.split(output, [\n",
        "        num_mixtures, num_mixtures * input_dim,\n",
        "        num_mixtures * input_dim\n",
        "    ], axis=-1)\n",
        "\n",
        "    mus = tf.reshape(mus, [-1, num_mixtures, input_dim])\n",
        "    prediction = scaler.inverse_transform(tf.reshape(mus[0, 0, :], (1, -1)).numpy())\n",
        "    generated_numbers = sorted(np.round(np.clip(prediction[0], 1, 50)).astype(int))\n",
        "\n",
        "    # Wartość oceny: jak blisko wygenerowana próbka jest wzorcowi\n",
        "    score = np.sum(np.abs(np.array(generated_numbers) - np.array(target_pattern)))\n",
        "    return -score  # Minimalizujemy różnicę (stąd minus)\n",
        "\n",
        "# Funkcja Metropolisa-Hastingsa dla MCMC\n",
        "def metropolis_hastings(model, scaler, target_pattern, num_samples=100_000, input_dim=3):\n",
        "    # Inicjalizacja początkowego punktu (wektora z losowymi danymi)\n",
        "    current_sample = np.random.normal(size=(1, input_dim))\n",
        "    accepted_samples = []\n",
        "\n",
        "    # Parametry łańcucha Markowa\n",
        "    current_score = evaluate_sample(model, scaler, current_sample, target_pattern)\n",
        "\n",
        "    with tqdm(total=num_samples, desc=\"MCMC Progress\", unit=\"sample\") as pbar:\n",
        "        for _ in range(num_samples):\n",
        "            # Propozycja nowego punktu (sample proposal)\n",
        "            proposed_sample = current_sample + np.random.normal(0, 0.1, size=current_sample.shape)\n",
        "\n",
        "            # Ocena nowego punktu\n",
        "            proposed_score = evaluate_sample(model, scaler, proposed_sample, target_pattern)\n",
        "\n",
        "            # Metropolisa-Hastingsa: akceptacja/odrzucenie\n",
        "            acceptance_prob = min(1, np.exp(current_score - proposed_score))\n",
        "\n",
        "            if np.random.rand() < acceptance_prob:\n",
        "                # Akceptujemy nową próbkę\n",
        "                current_sample = proposed_sample\n",
        "                current_score = proposed_score\n",
        "                accepted_samples.append(current_sample)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return np.array(accepted_samples)\n",
        "\n",
        "# Funkcja do wyszukiwania wzorca za pomocą MCMC\n",
        "# def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=10_000_000):\n",
        "def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=1_000_000):\n",
        "    print(f\"Rozpoczynam wyszukiwanie wzorca {target_pattern} przy użyciu MCMC...\")\n",
        "\n",
        "    accepted_samples = metropolis_hastings(model, scaler, target_pattern, num_samples=max_samples)\n",
        "\n",
        "    # Sprawdzanie, czy którykolwiek z wygenerowanych wzorców odpowiada poszukiwanemu\n",
        "    for sample in accepted_samples:\n",
        "        generated_numbers = sorted(np.round(np.clip(sample, 1, 50)).astype(int))\n",
        "        if generated_numbers == target_pattern:\n",
        "            print(f\"\\nZnaleziono wzorzec: {generated_numbers}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"\\nNie znaleziono wzorca w wygenerowanych próbkach.\")\n",
        "\n",
        "# Szukanie wzorca za pomocą MCMC\n",
        "print(f\"Szukanie wzorca dla seeda1: {seed1_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)\n",
        "\n",
        "print(f\"\\nSzukanie wzorca dla seeda2: {seed2_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "# Hello Qubit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ_JecKga2p"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://quantumai.google/cirq/start/start\"><img src=\"https://quantumai.google/site-assets/images/buttons/quantumai_logo_1x.png\" />View on QuantumAI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/colab_logo_1x.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/github_logo_1x.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/Cirq/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/download_icon_1x.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    import cirq\n",
        "\n",
        "    print(\"installed cirq.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4GQUN8MS7vt"
      },
      "outputs": [],
      "source": [
        "# Pick a qubit.\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Create a circuit that applies a square root of NOT gate, then measures the qubit.\n",
        "circuit = cirq.Circuit(cirq.X(qubit) ** 0.5, cirq.measure(qubit, key='m'))\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit several times.\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=20)\n",
        "print(\"Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNBShuQTFuu"
      },
      "source": [
        "# Congratulations\n",
        "You've just run your first Cirq program.\n",
        "\n",
        "To learn about running a circuit on a virtual machine that mimics existing quantum hardware, see [Quantum Virtual Machine](../simulate/quantum_virtual_machine.ipynb).\n",
        "\n",
        "If you would like to learn more about quantum computing, check out our [education page](https://quantumai.google/resources). The Full API reference for Cirq can be found [here](/reference/python/cirq). If you are looking for vendor specific information that can be found on our vendor sub-pages:\n",
        "\n",
        "\n",
        "  [Alpine Quantum Technologies](../hardware/aqt/getting_started.ipynb)\n",
        "  \n",
        "  [Pasqal](../hardware/pasqal/getting_started.ipynb)\n",
        "  \n",
        "  [IonQ](../hardware/ionq/getting_started.ipynb)\n",
        "  \n",
        "  [Azure](../hardware/azure-quantum/getting_started_honeywell.ipynb)\n",
        "  \n",
        "  [Rigetti](../hardware/rigetti/getting_started.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}