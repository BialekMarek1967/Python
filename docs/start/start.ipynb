{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXhctqjgXO7"
      },
      "source": [
        "##### Copyright 2022 The Cirq Developers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z2RJVa8qgXou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a06aeb1-d654-4a65-b107-dcc22d6e58e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  6]\n",
            " [ 6  7  8]\n",
            " [ 6 10 11]\n",
            " ...\n",
            " [ 2  6 11]\n",
            " [ 2  8  9]\n",
            " [ 3  7 10]]\n",
            "Epoch 1/1000\n",
            "\u001b[1m2231/3200\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: -5.3858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-e5ecbf857467>\", line 128, in <cell line: 128>\n",
            "    model.fit(X_scaled,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n",
            "    logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
            "    results = tracing_compilation.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1552, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e5ecbf857467>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Trening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m model.fit(X_scaled,\n\u001b[0m\u001b[1;32m    129\u001b[0m           \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm  # Dodano do dynamicznego wyświetlania postępu\n",
        "\n",
        "# Ustawienia liczby rdzeni CPU dla TensorFlow\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(100)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(100)\n",
        "\n",
        "# Ustawienia seedów\n",
        "seed1_datetime = datetime.strptime(\"2024-11-26 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 20 21 28 32 37 . 01 04\n",
        "seed2_datetime = datetime.strptime(\"2024-12-03 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 07 20 23 24 37 . 04 10\n",
        "\n",
        "seed1 = int(seed1_datetime.timestamp())\n",
        "seed2 = int(seed2_datetime.timestamp())\n",
        "\n",
        "# Ustawienie seedów dla powtarzalności wyników\n",
        "np.random.seed(seed1)\n",
        "tf.random.set_seed(seed1)\n",
        "\n",
        "# Definiowanie target pattern dla \"2024-11-26\"\n",
        "target_pattern = [1, 4, 12]\n",
        "\n",
        "# [3-12] Parametry generowania\n",
        "rows_3_12          = 100_000         # Liczba wierszy (do ustalenia)\n",
        "cols_3_12          = 3              # Liczba kolumn dla 1-12\n",
        "number_range_12    = range(1, 13)   # Zakres liczb od 1 do 12\n",
        "excluded_values_12 = target_pattern # Liczby do wykluczenia\n",
        "\n",
        "def generate_2d_array(rows, cols, number_range, excluded_values=None):\n",
        "    \"\"\" Generuje dwuwymiarową tablicę danych o podanych wymiarach. \"\"\"\n",
        "    if excluded_values is None:\n",
        "        excluded_values = []\n",
        "\n",
        "    # Tworzenie listy dostępnych liczb\n",
        "    available_numbers = [num for num in number_range if num not in excluded_values]\n",
        "\n",
        "    if len(available_numbers) < cols:\n",
        "        raise ValueError(\"Za mało dostępnych liczb do wygenerowania unikalnych kolumn.\")\n",
        "\n",
        "    # Generowanie danych\n",
        "    data = [\n",
        "        sorted(random.sample(available_numbers, cols))  # Generuje unikalne, sortowane rosnąco wartości w każdym wierszu\n",
        "        for _ in range(rows) ]\n",
        "\n",
        "    return np.array(data)\n",
        "\n",
        "# Generowanie tablicy\n",
        "data = generate_2d_array(rows_3_12, cols_3_12, number_range_12, excluded_values_12)\n",
        "print(data)\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Parametry modelu\n",
        "input_dim = X_scaled.shape[1]\n",
        "latent_dim = 12\n",
        "num_mixtures = 3\n",
        "\n",
        "# Funkcja straty MDN (Mixture Density Network)\n",
        "def mdn_loss(num_mixtures, output_dim):\n",
        "    def loss(y_true, outputs):\n",
        "        alphas, mus, sigmas = tf.split(outputs, [\n",
        "            num_mixtures, num_mixtures * output_dim, num_mixtures * output_dim\n",
        "        ],\n",
        "                                       axis=-1)\n",
        "        mus = tf.reshape(mus, [-1, num_mixtures, output_dim])\n",
        "        sigmas = tf.reshape(sigmas, [-1, num_mixtures, output_dim])\n",
        "        y_true = tf.expand_dims(y_true, axis=1)\n",
        "\n",
        "        gaussians = tf.exp(\n",
        "            -0.5 * tf.reduce_sum(tf.square(\n",
        "                (y_true - mus) / sigmas), axis=-1)) / (\n",
        "                    tf.reduce_prod(sigmas, axis=-1) * tf.sqrt(2.0 * np.pi))\n",
        "        weighted_gaussians = alphas * gaussians\n",
        "        nll = -tf.math.log(tf.reduce_sum(weighted_gaussians, axis=-1) + 1e-8)\n",
        "        return tf.reduce_mean(nll)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Funkcja tworząca model MDN + VAE\n",
        "def create_mdn_vae_model(input_dim, latent_dim, num_mixtures):\n",
        "    inputs = Input(shape=(input_dim, ))\n",
        "    h = Dense(64, activation='relu')(inputs)\n",
        "    h = Dense(32, activation='relu')(h)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim, ),\n",
        "               name='z')([z_mean, z_log_var])\n",
        "\n",
        "    h_decoder = Dense(32, activation='relu')(z)\n",
        "    h_decoder = Dense(64, activation='relu')(h_decoder)\n",
        "\n",
        "    alphas = Dense(num_mixtures, activation='softmax',\n",
        "                   name='alphas')(h_decoder)\n",
        "    mus = Dense(num_mixtures * input_dim, name='mus')(h_decoder)\n",
        "    sigmas = Dense(num_mixtures * input_dim,\n",
        "                   activation='softplus',\n",
        "                   name='sigmas')(h_decoder)\n",
        "\n",
        "    outputs = Lambda(lambda x: tf.concat(x, axis=-1),\n",
        "                     name='mdn_output')([alphas, mus, sigmas])\n",
        "\n",
        "    mdn_vae = Model(inputs, outputs, name='mdn_vae')\n",
        "    return mdn_vae\n",
        "\n",
        "# Tworzenie i kompilacja modelu\n",
        "model = create_mdn_vae_model(input_dim, latent_dim, num_mixtures)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=mdn_loss(num_mixtures, input_dim))\n",
        "\n",
        "# Trening\n",
        "model.fit(X_scaled,\n",
        "          X_scaled,\n",
        "          epochs=1000,\n",
        "          batch_size=100,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)\n",
        "\n",
        "# Funkcja do oceny próbki (używana w MCMC)\n",
        "def evaluate_sample(model, scaler, sample, target_pattern):\n",
        "    output = model.predict(sample, verbose=0)\n",
        "    alphas, mus, sigmas = tf.split(output, [\n",
        "        num_mixtures, num_mixtures * input_dim,\n",
        "        num_mixtures * input_dim\n",
        "    ], axis=-1)\n",
        "\n",
        "    mus = tf.reshape(mus, [-1, num_mixtures, input_dim])\n",
        "    prediction = scaler.inverse_transform(tf.reshape(mus[0, 0, :], (1, -1)).numpy())\n",
        "    generated_numbers = sorted(np.round(np.clip(prediction[0], 1, 50)).astype(int))\n",
        "\n",
        "    # Wartość oceny: jak blisko wygenerowana próbka jest wzorcowi\n",
        "    score = np.sum(np.abs(np.array(generated_numbers) - np.array(target_pattern)))\n",
        "    return -score  # Minimalizujemy różnicę (stąd minus)\n",
        "\n",
        "# Funkcja Metropolisa-Hastingsa dla MCMC\n",
        "def metropolis_hastings(model, scaler, target_pattern, num_samples=100_000, input_dim=3):\n",
        "    # Inicjalizacja początkowego punktu (wektora z losowymi danymi)\n",
        "    current_sample = np.random.normal(size=(1, input_dim))\n",
        "    accepted_samples = []\n",
        "\n",
        "    # Parametry łańcucha Markowa\n",
        "    current_score = evaluate_sample(model, scaler, current_sample, target_pattern)\n",
        "\n",
        "    with tqdm(total=num_samples, desc=\"MCMC Progress\", unit=\"sample\") as pbar:\n",
        "        for _ in range(num_samples):\n",
        "            # Propozycja nowego punktu (sample proposal)\n",
        "            proposed_sample = current_sample + np.random.normal(0, 0.1, size=current_sample.shape)\n",
        "\n",
        "            # Ocena nowego punktu\n",
        "            proposed_score = evaluate_sample(model, scaler, proposed_sample, target_pattern)\n",
        "\n",
        "            # Metropolisa-Hastingsa: akceptacja/odrzucenie\n",
        "            acceptance_prob = min(1, np.exp(current_score - proposed_score))\n",
        "\n",
        "            if np.random.rand() < acceptance_prob:\n",
        "                # Akceptujemy nową próbkę\n",
        "                current_sample = proposed_sample\n",
        "                current_score = proposed_score\n",
        "                accepted_samples.append(current_sample)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return np.array(accepted_samples)\n",
        "\n",
        "# Funkcja do wyszukiwania wzorca za pomocą MCMC\n",
        "# def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=10_000_000):\n",
        "def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=100_000):\n",
        "    print(f\"Rozpoczynam wyszukiwanie wzorca {target_pattern} przy użyciu MCMC...\")\n",
        "\n",
        "    accepted_samples = metropolis_hastings(model, scaler, target_pattern, num_samples=max_samples)\n",
        "\n",
        "    # Sprawdzanie, czy którykolwiek z wygenerowanych wzorców odpowiada poszukiwanemu\n",
        "    for sample in accepted_samples:\n",
        "        generated_numbers = sorted(np.round(np.clip(sample, 1, 50)).astype(int))\n",
        "        if generated_numbers == target_pattern:\n",
        "            print(f\"\\nZnaleziono wzorzec: {generated_numbers}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"\\nNie znaleziono wzorca w wygenerowanych próbkach.\")\n",
        "\n",
        "# Szukanie wzorca za pomocą MCMC\n",
        "print(f\"Szukanie wzorca dla seeda1: {seed1_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)\n",
        "\n",
        "print(f\"\\nSzukanie wzorca dla seeda2: {seed2_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "# Hello Qubit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ_JecKga2p"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://quantumai.google/cirq/start/start\"><img src=\"https://quantumai.google/site-assets/images/buttons/quantumai_logo_1x.png\" />View on QuantumAI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/colab_logo_1x.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/github_logo_1x.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/Cirq/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/download_icon_1x.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    import cirq\n",
        "\n",
        "    print(\"installed cirq.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4GQUN8MS7vt"
      },
      "outputs": [],
      "source": [
        "# Pick a qubit.\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Create a circuit that applies a square root of NOT gate, then measures the qubit.\n",
        "circuit = cirq.Circuit(cirq.X(qubit) ** 0.5, cirq.measure(qubit, key='m'))\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit several times.\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=20)\n",
        "print(\"Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNBShuQTFuu"
      },
      "source": [
        "# Congratulations\n",
        "You've just run your first Cirq program.\n",
        "\n",
        "To learn about running a circuit on a virtual machine that mimics existing quantum hardware, see [Quantum Virtual Machine](../simulate/quantum_virtual_machine.ipynb).\n",
        "\n",
        "If you would like to learn more about quantum computing, check out our [education page](https://quantumai.google/resources). The Full API reference for Cirq can be found [here](/reference/python/cirq). If you are looking for vendor specific information that can be found on our vendor sub-pages:\n",
        "\n",
        "\n",
        "  [Alpine Quantum Technologies](../hardware/aqt/getting_started.ipynb)\n",
        "  \n",
        "  [Pasqal](../hardware/pasqal/getting_started.ipynb)\n",
        "  \n",
        "  [IonQ](../hardware/ionq/getting_started.ipynb)\n",
        "  \n",
        "  [Azure](../hardware/azure-quantum/getting_started_honeywell.ipynb)\n",
        "  \n",
        "  [Rigetti](../hardware/rigetti/getting_started.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}