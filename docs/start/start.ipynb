{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BialekMarek1967/Python/blob/main/docs/start/start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXhctqjgXO7"
      },
      "source": [
        "##### Copyright 2022 The Cirq Developers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z2RJVa8qgXou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "58fbbc51-13c3-4013-c6c6-f61df5ae7487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  5  7]\n",
            " [ 6  8 10]\n",
            " [ 6  8 11]\n",
            " ...\n",
            " [ 9 10 11]\n",
            " [ 6  7  9]\n",
            " [ 6  8  9]]\n",
            "Epoch 1/500\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: -2.8103 - val_loss: -6.1553\n",
            "Epoch 2/500\n",
            "\u001b[1m575/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -6.7770"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-899432375dbf>\u001b[0m in \u001b[0;36m<cell line: 131>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Trening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m model.fit(X_scaled,\n\u001b[0m\u001b[1;32m    132\u001b[0m           \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m#          epochs=5000,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# https://colab.research.google.com/drive/1g6oSSNwNpdQKtlG0jJLT7QKXTWUJGRhS#scrollTo=8Cgm8Uw0XSHL\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm  # Dodano do dynamicznego wyświetlania postępu\n",
        "\n",
        "# Ustawienia liczby rdzeni CPU dla TensorFlow\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Ustawienia seedów\n",
        "seed1_datetime = datetime.strptime(\"2024-11-26 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 20 21 28 32 37 . 01 04\n",
        "seed2_datetime = datetime.strptime(\"2024-12-03 20:15:08\", \"%Y-%m-%d %H:%M:%S\") # 07 20 23 24 37 . 04 10\n",
        "\n",
        "seed1 = int(seed1_datetime.timestamp())\n",
        "seed2 = int(seed2_datetime.timestamp())\n",
        "\n",
        "# Ustawienie seedów dla powtarzalności wyników\n",
        "np.random.seed(seed1)\n",
        "tf.random.set_seed(seed1)\n",
        "\n",
        "# Definiowanie target pattern dla \"2024-11-26\"\n",
        "target_pattern = [1, 2, 3, 4, 5, 6, 7, 20, 21, 28, 32, 37]\n",
        "\n",
        "# [3-12] Parametry generowania\n",
        "rows_3_12          = 10         # Liczba wierszy (do ustalenia)\n",
        "# rows_3_12          = 10         # Liczba wierszy (do ustalenia)\n",
        "cols_3_12          = 10              # Liczba kolumn dla 1-12\n",
        "number_range_12    = range(1, 13)   # Zakres liczb od 1 do 12\n",
        "excluded_values_12 = target_pattern # Liczby do wykluczenia\n",
        "\n",
        "def generate_2d_array(rows, cols, number_range, excluded_values=None):\n",
        "    \"\"\" Generuje dwuwymiarową tablicę danych o podanych wymiarach. \"\"\"\n",
        "    if excluded_values is None:\n",
        "        excluded_values = []\n",
        "\n",
        "    # Tworzenie listy dostępnych liczb\n",
        "    available_numbers = [num for num in number_range if num not in excluded_values]\n",
        "\n",
        "    if len(available_numbers) < cols:\n",
        "        raise ValueError(\"Za mało dostępnych liczb do wygenerowania unikalnych kolumn.\")\n",
        "\n",
        "    # Generowanie danych\n",
        "    data = [\n",
        "        sorted(random.sample(available_numbers, cols))  # Generuje unikalne, sortowane rosnąco wartości w każdym wierszu\n",
        "        for _ in range(rows) ]\n",
        "\n",
        "    return np.array(data)\n",
        "\n",
        "# Generowanie tablicy\n",
        "data = generate_2d_array(rows_3_12, cols_3_12, number_range_12, excluded_values_12)\n",
        "print(data)\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Parametry modelu\n",
        "input_dim = X_scaled.shape[1]\n",
        "#latent_dim = 12\n",
        "latent_dim = 100\n",
        "num_mixtures = 3\n",
        "\n",
        "# Funkcja straty MDN (Mixture Density Network)\n",
        "def mdn_loss(num_mixtures, output_dim):\n",
        "    def loss(y_true, outputs):\n",
        "        alphas, mus, sigmas = tf.split(outputs, [\n",
        "            num_mixtures, num_mixtures * output_dim, num_mixtures * output_dim\n",
        "        ],\n",
        "                                       axis=-1)\n",
        "        mus = tf.reshape(mus, [-1, num_mixtures, output_dim])\n",
        "        sigmas = tf.reshape(sigmas, [-1, num_mixtures, output_dim])\n",
        "        y_true = tf.expand_dims(y_true, axis=1)\n",
        "\n",
        "        gaussians = tf.exp(\n",
        "            -0.5 * tf.reduce_sum(tf.square(\n",
        "                (y_true - mus) / sigmas), axis=-1)) / (\n",
        "                    tf.reduce_prod(sigmas, axis=-1) * tf.sqrt(2.0 * np.pi))\n",
        "        weighted_gaussians = alphas * gaussians\n",
        "        nll = -tf.math.log(tf.reduce_sum(weighted_gaussians, axis=-1) + 1e-8)\n",
        "        return tf.reduce_mean(nll)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Funkcja tworząca model MDN + VAE\n",
        "def create_mdn_vae_model(input_dim, latent_dim, num_mixtures):\n",
        "    inputs = Input(shape=(input_dim, ))\n",
        "    h = Dense(64, activation='relu')(inputs)\n",
        "    h = Dense(32, activation='relu')(h)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim, ),\n",
        "               name='z')([z_mean, z_log_var])\n",
        "\n",
        "    h_decoder = Dense(32, activation='relu')(z)\n",
        "    h_decoder = Dense(64, activation='relu')(h_decoder)\n",
        "\n",
        "    alphas = Dense(num_mixtures, activation='softmax',\n",
        "                   name='alphas')(h_decoder)\n",
        "    mus = Dense(num_mixtures * input_dim, name='mus')(h_decoder)\n",
        "    sigmas = Dense(num_mixtures * input_dim,\n",
        "                   activation='softplus',\n",
        "                   name='sigmas')(h_decoder)\n",
        "\n",
        "    outputs = Lambda(lambda x: tf.concat(x, axis=-1),\n",
        "                     name='mdn_output')([alphas, mus, sigmas])\n",
        "\n",
        "    mdn_vae = Model(inputs, outputs, name='mdn_vae')\n",
        "    return mdn_vae\n",
        "\n",
        "# Tworzenie i kompilacja modelu\n",
        "model = create_mdn_vae_model(input_dim, latent_dim, num_mixtures)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=mdn_loss(num_mixtures, input_dim))\n",
        "\n",
        "# Trening\n",
        "model.fit(X_scaled,\n",
        "          X_scaled,\n",
        "#          epochs=5000,\n",
        "#          batch_size=200,\n",
        "          epochs=500,\n",
        "          batch_size=50,\n",
        "          validation_split=0.2,\n",
        "          verbose=1)\n",
        "\n",
        "# Funkcja do oceny próbki (używana w MCMC)\n",
        "def evaluate_sample(model, scaler, sample, target_pattern):\n",
        "    output = model.predict(sample, verbose=0)\n",
        "    alphas, mus, sigmas = tf.split(output, [\n",
        "        num_mixtures, num_mixtures * input_dim,\n",
        "        num_mixtures * input_dim\n",
        "    ], axis=-1)\n",
        "\n",
        "    mus = tf.reshape(mus, [-1, num_mixtures, input_dim])\n",
        "    prediction = scaler.inverse_transform(tf.reshape(mus[0, 0, :], (1, -1)).numpy())\n",
        "    generated_numbers = sorted(np.round(np.clip(prediction[0], 1, 50)).astype(int))\n",
        "\n",
        "    # Wartość oceny: jak blisko wygenerowana próbka jest wzorcowi\n",
        "    score = np.sum(np.abs(np.array(generated_numbers) - np.array(target_pattern)))\n",
        "    return -score  # Minimalizujemy różnicę (stąd minus)\n",
        "\n",
        "# Funkcja Metropolisa-Hastingsa dla MCMC\n",
        "# def metropolis_hastings(model, scaler, target_pattern, num_samples=10_000_000, input_dim=3):\n",
        "# def metropolis_hastings(model, scaler, target_pattern, num_samples=8_000_000, input_dim=3):\n",
        "def metropolis_hastings(model, scaler, target_pattern, num_samples=5_000, input_dim=3):\n",
        "    # Inicjalizacja początkowego punktu (wektora z losowymi danymi)\n",
        "    current_sample = np.random.normal(size=(1, input_dim))\n",
        "    accepted_samples = []\n",
        "\n",
        "    # Parametry łańcucha Markowa\n",
        "    current_score = evaluate_sample(model, scaler, current_sample, target_pattern)\n",
        "\n",
        "    with tqdm(total=num_samples, desc=\"MCMC Progress\", unit=\"sample\") as pbar:\n",
        "        for _ in range(num_samples):\n",
        "            # Propozycja nowego punktu (sample proposal)\n",
        "            proposed_sample = current_sample + np.random.normal(0, 0.1, size=current_sample.shape)\n",
        "\n",
        "            # Ocena nowego punktu\n",
        "            proposed_score = evaluate_sample(model, scaler, proposed_sample, target_pattern)\n",
        "\n",
        "            # Metropolisa-Hastingsa: akceptacja/odrzucenie\n",
        "            acceptance_prob = min(1, np.exp(current_score - proposed_score))\n",
        "\n",
        "            if np.random.rand() < acceptance_prob:\n",
        "                # Akceptujemy nową próbkę\n",
        "                current_sample = proposed_sample\n",
        "                current_score = proposed_score\n",
        "                accepted_samples.append(current_sample)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return np.array(accepted_samples)\n",
        "\n",
        "# Funkcja do wyszukiwania wzorca za pomocą MCMC\n",
        "# def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=10_000_000):\n",
        "# def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=8_000_000):\n",
        "def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=5_000):\n",
        "    print(f\"Rozpoczynam wyszukiwanie wzorca {target_pattern} przy użyciu MCMC...\")\n",
        "\n",
        "    accepted_samples = metropolis_hastings(model, scaler, target_pattern, num_samples=max_samples)\n",
        "\n",
        "    # Sprawdzanie, czy którykolwiek z wygenerowanych wzorców odpowiada poszukiwanemu\n",
        "    for sample in accepted_samples:\n",
        "        generated_numbers = sorted(np.round(np.clip(sample, 1, 50)).astype(int))\n",
        "        if generated_numbers == target_pattern:\n",
        "            print(f\"\\nZnaleziono wzorzec: {generated_numbers}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"\\nNie znaleziono wzorca w wygenerowanych próbkach.\")\n",
        "\n",
        "# Szukanie wzorca za pomocą MCMC\n",
        "print(f\"Szukanie wzorca dla seeda1: {seed1_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)\n",
        "\n",
        "print(f\"\\nSzukanie wzorca dla seeda2: {seed2_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "# Hello Qubit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ_JecKga2p"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://quantumai.google/cirq/start/start\"><img src=\"https://quantumai.google/site-assets/images/buttons/quantumai_logo_1x.png\" />View on QuantumAI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/colab_logo_1x.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/github_logo_1x.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/Cirq/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/download_icon_1x.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    import cirq\n",
        "\n",
        "    print(\"installed cirq.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4GQUN8MS7vt"
      },
      "outputs": [],
      "source": [
        "# Pick a qubit.\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Create a circuit that applies a square root of NOT gate, then measures the qubit.\n",
        "circuit = cirq.Circuit(cirq.X(qubit) ** 0.5, cirq.measure(qubit, key='m'))\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit several times.\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=20)\n",
        "print(\"Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNBShuQTFuu"
      },
      "source": [
        "# Congratulations\n",
        "You've just run your first Cirq program.\n",
        "\n",
        "To learn about running a circuit on a virtual machine that mimics existing quantum hardware, see [Quantum Virtual Machine](../simulate/quantum_virtual_machine.ipynb).\n",
        "\n",
        "If you would like to learn more about quantum computing, check out our [education page](https://quantumai.google/resources). The Full API reference for Cirq can be found [here](/reference/python/cirq). If you are looking for vendor specific information that can be found on our vendor sub-pages:\n",
        "\n",
        "\n",
        "  [Alpine Quantum Technologies](../hardware/aqt/getting_started.ipynb)\n",
        "  \n",
        "  [Pasqal](../hardware/pasqal/getting_started.ipynb)\n",
        "  \n",
        "  [IonQ](../hardware/ionq/getting_started.ipynb)\n",
        "  \n",
        "  [Azure](../hardware/azure-quantum/getting_started_honeywell.ipynb)\n",
        "  \n",
        "  [Rigetti](../hardware/rigetti/getting_started.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}