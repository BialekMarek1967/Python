{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXhctqjgXO7"
      },
      "source": [
        "##### Copyright 2022 The Cirq Developers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RJVa8qgXou"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ustawienia seedów\n",
        "seed1_datetime = datetime.strptime(\"2024-11-26 20:15:08\", \"%Y-%m-%d %H:%M:%S\")\n",
        "seed1 = int(seed1_datetime.timestamp())\n",
        "np.random.seed(seed1)\n",
        "tf.random.set_seed(seed1)\n",
        "\n",
        "# Definiowanie target pattern\n",
        "target_pattern = [1, 2, 3, 4, 5, 20, 21, 28, 32, 37]\n",
        "\n",
        "# Parametry danych\n",
        "rows_10_50 = 500_000\n",
        "cols_10_50 = len(target_pattern)  # Liczba kolumn = długość target_pattern\n",
        "number_range_50 = range(1, 51)\n",
        "excluded_values_50 = target_pattern\n",
        "\n",
        "# Funkcja generująca dane\n",
        "def generate_2d_array(rows, cols, number_range, excluded_values=None):\n",
        "    if excluded_values is None:\n",
        "        excluded_values = []\n",
        "    available_numbers = [num for num in number_range if num not in excluded_values]\n",
        "    if len(available_numbers) < cols:\n",
        "        raise ValueError(\"Za mało dostępnych liczb.\")\n",
        "    data = [sorted(random.sample(available_numbers, cols)) for _ in range(rows)]\n",
        "    return np.array(data)\n",
        "\n",
        "# Generowanie tablicy\n",
        "data = generate_2d_array(rows_10_50, cols_10_50, number_range_50, excluded_values_50)\n",
        "print(data)\n",
        "\n",
        "# Skalowanie danych\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Parametry modelu\n",
        "input_dim = cols_10_50\n",
        "latent_dim = 500_000\n",
        "num_mixtures = 1_000\n",
        "\n",
        "# Funkcja straty MDN\n",
        "def mdn_loss(num_mixtures, output_dim):\n",
        "    def loss(y_true, outputs):\n",
        "        alphas, mus, sigmas = tf.split(outputs, [\n",
        "            num_mixtures, num_mixtures * output_dim, num_mixtures * output_dim\n",
        "        ],\n",
        "                                       axis=-1)\n",
        "        mus = tf.reshape(mus, [-1, num_mixtures, output_dim])\n",
        "        sigmas = tf.reshape(sigmas, [-1, num_mixtures, output_dim])\n",
        "        y_true = tf.expand_dims(y_true, axis=1)\n",
        "        gaussians = tf.exp(\n",
        "            -0.5 * tf.reduce_sum(tf.square(\n",
        "                (y_true - mus) / sigmas), axis=-1)) / (\n",
        "                    tf.reduce_prod(sigmas, axis=-1) * tf.sqrt(2.0 * np.pi))\n",
        "        weighted_gaussians = alphas * gaussians\n",
        "        nll = -tf.math.log(tf.reduce_sum(weighted_gaussians, axis=-1) + 1e-8)\n",
        "        return tf.reduce_mean(nll)\n",
        "    return loss\n",
        "\n",
        "# Tworzenie modelu MDN + VAE\n",
        "def create_mdn_vae_model(input_dim, latent_dim, num_mixtures):\n",
        "    inputs = Input(shape=(input_dim,))\n",
        "    h = Dense(64, activation='relu')(inputs)\n",
        "    h = Dense(32, activation='relu')(h)\n",
        "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    h_decoder = Dense(32, activation='relu')(z)\n",
        "    h_decoder = Dense(64, activation='relu')(h_decoder)\n",
        "\n",
        "    alphas = Dense(num_mixtures, activation='softmax', name='alphas')(h_decoder)\n",
        "    mus = Dense(num_mixtures * input_dim, name='mus')(h_decoder)\n",
        "    sigmas = Dense(num_mixtures * input_dim, activation='softplus', name='sigmas')(h_decoder)\n",
        "\n",
        "    outputs = Lambda(lambda x: tf.concat(x, axis=-1), name='mdn_output')([alphas, mus, sigmas])\n",
        "\n",
        "    mdn_vae = Model(inputs, outputs, name='mdn_vae')\n",
        "    return mdn_vae\n",
        "\n",
        "# Tworzenie i kompilacja modelu\n",
        "model = create_mdn_vae_model(input_dim, latent_dim, num_mixtures)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=mdn_loss(num_mixtures, input_dim))\n",
        "\n",
        "# Trening modelu\n",
        "model.fit(X_scaled, X_scaled, epochs=500_000, batch_size=500_000, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Funkcja oceny próbki\n",
        "def evaluate_sample(model, scaler, sample, target_pattern):\n",
        "    output = model.predict(sample, verbose=0)\n",
        "    alphas, mus, sigmas = tf.split(output, [\n",
        "        num_mixtures, num_mixtures * input_dim, num_mixtures * input_dim\n",
        "    ], axis=-1)\n",
        "    mus = tf.reshape(mus, [-1, num_mixtures, input_dim])\n",
        "    prediction = scaler.inverse_transform(tf.reshape(mus[0, 0, :], (1, -1)).numpy())\n",
        "    generated_numbers = sorted(np.round(np.clip(prediction[0], 1, 50)).astype(int))\n",
        "    score = np.sum(np.abs(np.array(generated_numbers) - np.array(target_pattern)))\n",
        "    return -score\n",
        "\n",
        "# Funkcja MCMC\n",
        "def metropolis_hastings(model, scaler, target_pattern, num_samples=500_000, input_dim=10):\n",
        "    current_sample = np.random.normal(size=(1, input_dim))\n",
        "    accepted_samples = []\n",
        "    current_score = evaluate_sample(model, scaler, current_sample, target_pattern)\n",
        "\n",
        "    with tqdm(total=num_samples, desc=\"MCMC Progress\", unit=\"sample\") as pbar:\n",
        "        for _ in range(num_samples):\n",
        "            proposed_sample = current_sample + np.random.normal(0, 0.1, size=current_sample.shape)\n",
        "            proposed_score = evaluate_sample(model, scaler, proposed_sample, target_pattern)\n",
        "            acceptance_prob = min(1, np.exp(current_score - proposed_score))\n",
        "            if np.random.rand() < acceptance_prob:\n",
        "                current_sample = proposed_sample\n",
        "                current_score = proposed_score\n",
        "                accepted_samples.append(current_sample)\n",
        "            pbar.update(1)\n",
        "    return np.array(accepted_samples)\n",
        "\n",
        "# Wyszukiwanie wzorca\n",
        "def find_pattern_with_mcmc(model, scaler, target_pattern, max_samples=500_000):\n",
        "    print(f\"Rozpoczynam wyszukiwanie wzorca {target_pattern} przy użyciu MCMC...\")\n",
        "    accepted_samples = metropolis_hastings(model, scaler, target_pattern, num_samples=max_samples)\n",
        "    for sample in accepted_samples:\n",
        "        generated_numbers = sorted(np.round(np.clip(sample[0], 1, 50)).astype(int))\n",
        "        if generated_numbers == target_pattern:\n",
        "            print(f\"\\nZnaleziono wzorzec: {generated_numbers}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"\\nNie znaleziono wzorca w wygenerowanych próbkach.\")\n",
        "\n",
        "find_pattern_with_mcmc(model, scaler, target_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "# Hello Qubit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ_JecKga2p"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://quantumai.google/cirq/start/start\"><img src=\"https://quantumai.google/site-assets/images/buttons/quantumai_logo_1x.png\" />View on QuantumAI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/colab_logo_1x.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/Cirq/blob/main/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/github_logo_1x.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/Cirq/docs/start/start.ipynb\"><img src=\"https://quantumai.google/site-assets/images/buttons/download_icon_1x.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    import cirq\n",
        "\n",
        "    print(\"installed cirq.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4GQUN8MS7vt"
      },
      "outputs": [],
      "source": [
        "# Pick a qubit.\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "\n",
        "# Create a circuit that applies a square root of NOT gate, then measures the qubit.\n",
        "circuit = cirq.Circuit(cirq.X(qubit) ** 0.5, cirq.measure(qubit, key='m'))\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit several times.\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=20)\n",
        "print(\"Results:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNBShuQTFuu"
      },
      "source": [
        "# Congratulations\n",
        "You've just run your first Cirq program.\n",
        "\n",
        "To learn about running a circuit on a virtual machine that mimics existing quantum hardware, see [Quantum Virtual Machine](../simulate/quantum_virtual_machine.ipynb).\n",
        "\n",
        "If you would like to learn more about quantum computing, check out our [education page](https://quantumai.google/resources). The Full API reference for Cirq can be found [here](/reference/python/cirq). If you are looking for vendor specific information that can be found on our vendor sub-pages:\n",
        "\n",
        "\n",
        "  [Alpine Quantum Technologies](../hardware/aqt/getting_started.ipynb)\n",
        "  \n",
        "  [Pasqal](../hardware/pasqal/getting_started.ipynb)\n",
        "  \n",
        "  [IonQ](../hardware/ionq/getting_started.ipynb)\n",
        "  \n",
        "  [Azure](../hardware/azure-quantum/getting_started_honeywell.ipynb)\n",
        "  \n",
        "  [Rigetti](../hardware/rigetti/getting_started.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}